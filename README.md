# Academic_Words
Some sparkling academic words abstracted from papers (Continuously Updating)

```
论文词汇积累

vanilla 香草，论文意思 普通的~   e.g, vanilla attention network  vanilla RNN 纯净版RNN

untie 解开，论文意思 解决了~   e.g,  A unties the sequential dependency on B   A解决了B上面的序列依赖问题

improve sth.   e.g, improve the parallelization capability

relieve sth.  e.g, relieve the long distance dependency problem.

solely 仅仅  e.g, sth based solely on attention mechanisms and ***

extraordinary results 卓越的成果

To the best of our knowledge 据我们所知

identical results 相同的结果

consume 接收 e.g, RNNs can only consume the input and generate the output sequentially

By reason of = due to 由于 e.g, BRO being able to obtain natural language responses, natural answers are more favored in real world question answering systems./// due to the subjectivity, randomness, and onesidedness of questions and answers written by the ordinary Internet users,

specifically Particularly Especially 具体来说 e.g, specifically// particularly , ***

employ=utilize=adopt 采用 e.g, we employ/utilize/adopt two practical measures to automatically measure the quality  

be employed for 被用作** e.g, curriculum learning is employed for training NAG model

in the form of 以什么形式 e.g, compared with the typical question answering systems which merely obtain exact answers in the form of entities or phrases

take***as*** 把什么当做什么 e.g, it takes word sequences as input

heavily depends 很大程度上依赖 

solitary 单独的，纯粹的 e.g, solitary entity

intractable task 棘手的问题

poorly 否定 e.g, the state-of-the-art automatic metrics are poorly related to human evaluation in natural language generation tasks

moreover = Furthermore 此外 e.g, Moreover, human evaluation is impractical for scalable machine learning models.

reduced sharply 急速下降

take ** into consideration 把什么考虑在内 e.g, if we only take high-quality QA-pairs into consideration

solitary/onesided answers 孤立的/片面的答案

contributes to sth/doing sth 有助于 e.g, the entity also contributes to learning the interaction with the knowledge base (KB) , which should not be directly and completely removed from the learning corpora.

learning corpora 训练语料



Therefore=hence 因此 <=> 后面用 thereafter 之后

in order to 为了  in order to take full use of the learning data, as well as to robustly deal with the noisy and uneven-quality QA-pairs, inspired by Sachan and Xing，we propose a natural answer generation framework based on curriculum learning

be supposed to 被假设 e.g, answers are supposed to be more complex and higher-quality ones

distill 蒸馏出 e.g, distilling correct entities from the low-quality and short answers to interact with the KB

In brief 简单说 e.g, In brief, our main contributions are as follows

fusion task 融合的任务

Meanwhile 与此同时 e.g,  Meanwhile, the system needs to interact with KB for obtaining correct answer entities, which retrieves a set of candidate facts and generates correct answers using corresponding facts

In other words 换句话说 e.g, In other words, answering words consist of both common words (from vocabulary) and KB-words (from retrieved facts).

consist of 由什么组成 e.g, answering words consist of both common words (from vocabulary) and KB-words (from retrieved facts).

numerical representations 数字形式的表征

heuristic strategies 启发式的策略

achieve high performance 获得更好的表现

nevertheless = Nonetheless = In contrast = by contrast 然而

hardly 很难的 e.g, it hardly reflected from the training loss because of the difficult evaluation of the GNA

plausibility 合理性 e.g, Evaluate the plausibility of a target-side fact based on existing information in a knowledge base

arbitrary graphs 任意的图

eventually 最终的  e.g, This will eventually result in a graph convolutional network

leverage 利用 e.g, In a nutshell, obtain higher-level representations of a node i by leveraging its neighbourhood, Ni !

efficiency 效率 e.g, Computational and storage efficiency

Specify 指定 e.g, Specifying different importances to different neighbours

aggregate 合计 e.g,We can then easily aggregate neighbourhoods through multiplying by the adjacency matrix!

correction 修正 e.g, this update rule discards the central node. Provide a simple correction

alleviate 缓解 e.g, alleviate the previous issues；； this approach aims at alleviating the low adequacy of some of the translations produced by an NMT system.

conversely 相反地 e.g, The graph convolutional policy network (GCPN) represents, conversely, a sequential generation method

partially 局部的 

explicit 显性的 <==> implicit 隐性的

more than a diversion 不仅仅是一个消遣  more than a 不仅仅是

sophisticated 复杂的 e.g,  they rely on a much more sophisticated understanding of the user’s intent

play a crucial role 起到重要作用

collectively 统一地 e.g, We’ll then turn to a set of tasks collectively called text normalization, in which text normalization regular expressions play an important part.

negation 否定 e.g, To indicate a negation inside of square brackets , and just to mean a caret

More technically 更技术的讲

for simplicity 为了简单起见

bear 经受 e.g, but its application to translation bears further discussion

remainder 余下部分 e.g, the remainder of the paper is organized as follows

avenues 道路 e.g, we provide avenues for further work

Preliminary 准备，预赛 e.g, in the preliminary stage

leverage 利用 e.g, To reduce the number of parameters and leverage potential correlation among fine-grained edge types, we …

deployed—deploy<==>employ 使用、配置 e.g, State-of-the-art neural machine translation models are deployed and used following the high-level framework provided by Keras.

 Given its 鉴于其 e.g,  Given its high modularity and flexibility , it also has been extended to tackle different problems ,such as image and video captioning, sentence classification and visual question answering.

striking difference 显著的差异


explicable == interpretable 可解释的  e.g, Do NMT models extract linguistic features from raw data and exploit them in explicable ways?

when it comes to 在什么方面 e.g, RNNs are powerful models of language and have no rivals when it comes to capturing implicit structure

consensus 一致的 e.g, the first application of machine translation system combination used a consensus decoding strategy relying on a confusion network.

relies directly on 直接取决于

 extremely 相当的 = remarkably  e.g, PBFD is extremely costly to perform during NMT decoding but rather feasible after it on a selected set of diverse hypotheses.

salient 突出的,显著地 e.g, we show our method improves NMT translation results up to 6 BLEU points on three narrow domain translation tasks where repetitiveness of the target sentences is particularly salient.

 compare favourably to other alternative method 和其他替代方法相比，他是优于其他的

ameliorate 减缓  e.g,  A number of methods have been proposed to ameliorate these problems

discrete translation lexicons 离散的翻译词典

conducive to 更有利于 e.g, this method adjust model structures to be more conducive to generalisation

appealing 吸引人的 e.g, NN approaches to machine translation are appealing for their single model, end2end training process 

competitive 有竞争力的 e.g, It have demonstrated competitive performance performance compared to earlier statistical approaches.

disproportionately 不成比例地 e.g, something favours common words disproportionately

surpassing 超越 e.g, this approach surpassing phrase-based translation in nearly all settings .

converts 转换 e.g, the encoder converts the words of the source sentence into word embeddings , then into a sequence of hidden states


 intuitively 直觉地 e.g, we can intuitively interpret the terms as follows.

propose instead 相反地提出 e.g, we propose instead to use a simple feedforward neural network that is trained jointly with the rest of the NMT model to generate a target word 

scenarios 场景 e.g, we consider two scenarios 

aforementioned 之前提到过的 e.g, we can achieve competitive results in the aforementioned scenarios when translating from english to german and vietnamese.

Notably 显著地，尤其 e.g, Notably, we have advanced state-of-the-art results in the IWSLT english-german MT track by up to 5.2 BLEU points

conceptually 概念上来说 e.g, It is conceptually simple

emit 放射 e.g, NMT starts emitting one target word at a time until a special end-of-sentence symbol is produced.

simplicity 朴素、简单 e.g, such simplicity leads to several advantages

intricate 复杂的 e.g, NMT unlike the highly intricate decoders in SMT

in the case of 在什么情况下 e.g, NMT has been applied to mostly formal texts as in the case of the WMT translation tasks.

off-the-shelf 现成的 e.g, NMT models trained with an off-the-shelf framework can achieve competitive performance compared to the IWSLT baseline.

regarding sth  考虑到*** e.g, Regarding the aforementioned NMT approach,

problematic 有问题的 e.g, This is mostly due to the fact that the model has to encode the entire source information into single fixed-dimensional vector h, which is problematic for long variable-length sentences.

Concretely 具体的 e.g, concretely,  the attention mechanism will set ****

Additionally 额外地 e.g, Additionally, by ensembling multiple models as done 

cumbersome 笨重的 e.g, cumbersome model 笨重的模型

significant loss 明显的损失

scratch 抓、凑合的、碰巧、草稿用的 from scratch 草稿，从头开始的 start from scratch 从头开始，白手起家 Up to scratch 达到标准 scratch the surface 只做了肤浅的研究

Compact 紧凑的

deployment stage  在使用阶段（机器学习模型的测试阶段）

latency 潜在因素

stringent 严格的 e.g, Deployment to a large number of users , however, has much more stringent requirements on latency and computational resources.

pioneer 倡导、先驱 e.g, A version of this strategy has already been pioneered by R and his collaborators

demonstrate convincingly 令人信服地证明 

generally accepted 大众都接受的 e.g, it is generally accepted that ***

Despite this 尽管如此

arithmetic or geometric mean 算术或者几何的均值

procedure 过程 == process(n.)

compilation 编译，编纂 e.g, this thesis is thus a compilation of studies on exploiting multilingualism and knowledge transfer for low resource machine translation . 

twofold 两点、双倍的 e.g, Our aim is twofold

paradigms 范式

detail 动词描述 详实 e.g, we detail on SMT and NMT since this thesis revolves around these two paradigms

continuously 连续地 e.g, he continuously encouraged me throughout the three years

with respect to = with regard to 关于什么方面 e.g, NMT systems have a steeper learning curve with respect to the amount of training data, resulting in worse quality in low-resource setting

Notably 值得注意的 e.g, Notably, they dropped the attention mechanism in favour of a shared vector space where to represent both text and multi-model information

separately 分别地  e.g, at run time , they separately translate input strings f and g into candidate target string e1 and e2, then select the best one of the two.

pose a problem 摆出问题，产生问题
much less effective <—> much more effective 比较小的效果 ，比较大的效果 e.g, The enc-dec framework for NMT has been shown effective in large data scenarios, but is more less effective for low-resource languages.

lay the emphasis on 把重点放在** e.g, In particular, we lay the emphasis on investigating  the topic of the domain adaptation for such systems.

to the end 到最后 = in the end = finally 

refined 精制的 e.g, One more refined attempt is first training a NMT system on larger amounts of out-of-domain data.

overcome 克服 e.g, As F point out, this might lead to overfitting , and to overcome this issue.

propose 提出 e.g, they propose using an ensemble of the out-of-domain and the domain-adapted model at translation time.

yield 收获、得到 e.g, it could yield further improvements 

proliferation 繁殖 e.g, there is now a proliferation of toolkits for NMT

dire 坏的= bad = extremely serious consequence =terrible 

delve 深入研究 e.g, After delving into Chinese lexical knowledge , we sketch 68 implicit morphological relations and 28 explicit semantic relations

on par with 和什么一致=synergistically  e.g, Our eager translation model is low-latency, writing target tokens as soon as it reads the first source token.

circumvent 智取，规避  e.g, To circumvent this problem.

circumvented 规避 e.g, We demonstrate that this problem can be circumvented. 

To the best of our knowledge 据我们所知

synergistically 表现为协同作用 e.g, the proposed method worked synergistically with Luong’s further training method.

orthogonal 正交的，没关系的 = heterogeneous 异源的  e.g, it indicate that the proposed method and A’s method are essentially orthogonal. ////   Neural Machine Translation (NMT) models are often trained on heterogeneous mixtures of domains, from news to parliamentary proceedings, each with unique distributions and language.

the lower the better 越什么越什么句型 可以做表语 e.g, The original cross-entropy is the lower the better, and we swap the in and out order.

transpose 转置，交换 e.g, we transpose batch normalisation into layer normalisation by computing the mean and variance used for normalisation from all of the summed inputs to the neurons in a layer on a single training case.

disambiguate  消除歧义 e.g, Intuitively, part-of-speech annotation of the english input could disambiguate between verb, noun, and adjective meaning of close.

adequately 充分地 = fully = completely 

shotcuts 捷径 e.g, recurrent units in LSTMs or GRUs normally introduce different gates to create shotcuts for gradient information to pass through

Notwithstanding 尽管 e.g, Notwithstanding the capacity of these gated recurrent networks in learning long-distance dependencies, they use remarkably more matrix transformations than SRNN. 

so as to 以便 e.g, ATR also use gates to bypass the vanishing gradient problem so as to capture long-range dependencies.

an influx 什么的大量涌入 e.g, an influx to workforce will have an immediate effect on productivity and GDP.

notorious 臭名昭著的 bottleneck 瓶颈 e.g, it is a notorious bottleneck of the RNN .

roughly 概略地，粗糙地 e.g, we roughly split the embedding vector one-to-two between the lemma feature and the word feature.

ubiquitous 普遍存在的 e.g, GRNNs have become ubiquitous in natural language processing.

 interpretable 可解释的 .e.g, RANS can directly select which part of each input element to retain at each time step, leading to a highly expressive yet interpretable model.

 be consistent with 和什么一致 e.g, a should be consistent with other players.

 serves to 用于 e.g, However , Content layer is very simple and only serves to allow different input vector and state vector dimensions.

Similarly 相似地

auxiliary 附属的，辅助的 e.g, Rather than viewing the gating mechanism as simply an auxiliary mechanism to address a learning problem, we present an alternate of view of LSTMs.

 it is possible to 有可能做什么 e.g, We argue that it is possible to reinterpret LSTMs that emphasises the modeling strengths of the gates.

To better understand *** 为了更好的理解*** 

To this end === on this account 为此 e.g, To this end, we propose three strategies which exploit the unique features of each target language and keep as many parameters shared as possible.

correspondingly 与此对应地 e.g, Correspondingly , the structural difference between target languages can be well captured.

experimental results 实验结果 e.g, the experimental results demonstrate that the three strategies can significantly outperform the baseline multilingual models.

noticeably 显著地 e.g, Baseline fine-tuning starts to noticeably overfit 

property 性质，财产 e.g, This property not only allows us to trace each state back to those inputs which contribute more, but also establishes unnormalised forward self-attention between the current state and all its previous inputs.

hold on 保持，不挂断 e.g, Our conclusions still hold on all these tasks.

different from them 和他们不同，与以上不同 e.g, Different from them, ATR introduces different operations (i.e., addition and subtraction) between the weighted history and input to distinguish the input and forget gate.

transparently 显然地 e.g, It is also able to transparently model long-distance dependencies.

encouraging 令人鼓舞的 e.g, Experiments show encouraging performance of our model on CH-EN translation.

quasi- 准、类似（前缀） e.g, We introduce quasi-recurrent neural networks (QRNNs) , an approach to neural sequence modelling that 

minimalist 极简主义的，极简主义 e.g,  which apply in a minimalist recurrent pooling function that applies in parallel across channels.

exert *** impacts on *** 施加，发挥影响  e.g, Intuitively, words in a sentence are related to its domain to varying degrees, so that they will exert disparate impacts on the multi-domain NMT modeling.

devote to 致力于 e.g, We devote to distinguishing and exploiting word-level domain contexts for multi-domain classification tasks and improve NMT as follows.

aggregator 汇聚者，集合器 e.g, With annotations, we employ two attention-like aggregators to generate the semantic representations of sentence x.

efficacy 功效 e.g, We demonstrate the efficacy of these techniques by merging pairs of domains in three languages: CH, FR, JP.

composite data 合成的数据 e.g, After training on composite data, each approach outperforms its domain specific counter parts.

likewise 同样地 e.g, Likewise, we stack a domain classifier on top of E.

formally 正式地 e.g, Formally, we define the objective function of NMT as follows.

let alone 更不用说 e.g, There is very little data (even monolingual , let alone bilingual or parallel) for each speaker, compared to millions of sentences usually used in NMT.

 In practical terms 在实践中 e.g, In practical terms, this means that we cannot share information among users.

partitioned into 分割成(几块) e.g, The data is then partitioned into training , validation and test sets.

aforementioned 前面提到的 e.g, The aforementioned methods differ from ours in that they require explicit signal for which labelling is needed.

non-trivial 重大的== not trivial e.g, It is non-trivial to design the training process.

make trade-off 作出取舍 e.g, We have to make a trade-off between the translation quality and the computation cost.

dubbed as 被称作 e.g, In particular , we design a novel framework, Explicit interAction Model (dubbed as EXAM).

explored (still being explored) 仍在被探索 e.g, But for NMT, forest-based methods are still being explored

topological ordering 拓扑排序 e.g, Because of the structural complexity of forests, the lack of appropriate topological ordering, and the hyperedge-attachment nature of weights, it is not trivial to linearise a forest.

effectiveness 有效性 e.g, Experiments demonstrate the effectiveness of our method

Preliminaries 前言 一般在Introduction之后，在正式说明自己方法之前 

asynchronous  异步的 e.g,

simple yet effective 简单有效的 
generic 通用的 e.g, As a result, generic LSTMs cannot maintain the quality of their later predictions, and this is a serious problem especially when the input sequence is long.

Revisiting 回顾 e.g, Revisiting the generic LSTM

in some sense 某种意义上 e.g, thus it is in some sense an ensemble.

to date 到目前为止 e.g, However, there are major differences between our idea and the neural network ensembles reported in the literature to date.

intractable 棘手的 e.g, The exact inference for an agreement model is usually intractable

essence 本质 e.g, It is impossible to calculate both left-to-right and right-to-left model scores simultaneously for each partial sequence due to the essence of RNNs.

comfortably outperforms 很轻松地超过 e.g, Although a single NMT model comfortably outperforms the Moses and Moses-hier baselines.

be consistent with 和什么一致 e.g, We can see that NMT-r2l-10 is not necessarily better than NMT-r2l-5 ,which is consistent with the findings reported in(Zhou et al. 2002)

consistently 始终如一地 e.g, The proposed joint model consistently outperformed the strongest neural baseline.

fruitful 富有成效的 e.g, We would like to thanks Rico Sennrich for fruitful discussion.

leaving  *** unexploited 没有使用 e.g, The NMT decoders adopt recurrent neural networks to perform translation in a left-to-right manner, leaving the target-side contexts generated from right-to-left unexploited during translation.

readily 容易地 e.g., In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems.

a line of 一系列的 e.g, Recently, a line of research efforts have been devoted to incorporate additional information by extracting syntactic information such as the phrase structure of a source sentence by utilizing attention mechanisms for inputs sets, and by encoding sentences recursively as trees.

inadequate 不够的 e.g, current Seq2Seq and Tree2Seq may be inadequate to handle.

non-trivially 不一般地,重要地 e.g, We non-trivially generalize it to copy  

 a surge of approaches 激增的方法 e.g, There has been a surge of approaches that seek to learn the representations of graph nodes or entire graphs, based on Graph Neural Networks that extend well-known network architectures including RNN and CNN to graph data.

it is essentially *** 它本质上是 e.g, It is essentially a prediction model that learns to predict a sequence embedded in graph while our approach is a generative model that learns a mapping between graph inputs and sequence outputs.

analogy 类比 e.g, a good analogy that can be drawn between our proposed G2S and GGS-NNs is the relationship between convolutional S2S and RNN.

whilst == while 同时，当什么时候 e.g, The sequence decoder takes both the G embedding and N embedding as input and employs attention over the N embedding whilst generating sequences.

effectiveness and efficiency 效率和效力 e.g, We conduct experiments to demonstrate the effectiveness and efficiency of the proposed method.

arguably 可辩证地 e.g, Among these tasks, Task 19 is arguably the most challenging task which reports an accuracy of less than 20% for all methods that do not use strong supervision.

solely = only 仅仅 e.g, However , in this work we solely focus on dependency syntax and leave more general investigation for future work.

rivalling rival的动名词形式可比较 可比较，可匹敌 e.g, NMT models have achieved impressive results, rivalling traditional translation formation.

overly 过度地 e.g, However their modelling formulation is overly simplistic.

surpassing 超过 e.g, 

Analogously 类似地 

Shows superior results 表现出更好的结果 e.g, On a standard benchmark, our model shows superior results to existing methods in the literature.

 tremendously 非常地 e.g, In addition, it has been shown that NMT performance drops  tremendously in low-resource scenarios.

in-house system 内部系统 e.g., Our PBMT system is an in-house system similar to Moses.

vis-a-vis 和什么比较 e.g, End2end approach to machine translation has achieved competitive results vis-a-vis statistical machine translation on various language pairs.

```
